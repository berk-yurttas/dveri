# ğŸš€ Automatic Performance Optimizations

## TL;DR - It Just Works!â„¢

All performance optimizations are **automatically applied** to your API requests:

- âœ… **All GET requests** â†’ Cached for 5 minutes
- âœ… **All widget POST requests** â†’ Queued (max 6 concurrent)
- âœ… **Request deduplication** â†’ Multiple identical requests = 1 API call
- âœ… **30-second timeout** â†’ No more hanging requests

**You don't need to change any existing code!**

---

## ğŸ“ What This Means for You

### Before (Manual Configuration):
```typescript
// You had to explicitly enable caching
const options = await api.get('/data/infrastructure', undefined, { 
  useCache: true, 
  cacheDuration: 5 * 60 * 1000 
})

// You had to explicitly enable queue
const data = await api.post('/data/widget', {...}, {...}, { useQueue: true })
```

### After (Automatic - Current):
```typescript
// Just write normal API calls - optimizations happen automatically!
const options = await api.get('/data/infrastructure')
const data = await api.post('/data/widget', {...})
```

---

## ğŸ¯ How It Works

### 1. **GET Requests = Automatic Cache**

```typescript
// First call - fetches from server
const data1 = await api.get('/data/infrastructure')  // â³ 200ms

// Second call within 5 minutes - returns from cache
const data2 = await api.get('/data/infrastructure')  // âš¡ <1ms (CACHE HIT!)

// After 5 minutes - fetches fresh data
const data3 = await api.get('/data/infrastructure')  // â³ 200ms (cache expired)
```

**Cache Behavior:**
- âœ… Default duration: **5 minutes**
- âœ… Automatic deduplication: Multiple simultaneous requests â†’ 1 API call
- âœ… Per-endpoint caching: `/data/products` and `/data/companies` cache separately
- âœ… Memory-based: Cleared on page refresh

### 2. **Widget Requests = Automatic Queue**

```typescript
// Even if 20 widgets load simultaneously:
// Widget 1-6: Execute immediately
// Widget 7-20: Queued automatically, execute as slots open

const data = await api.post('/data/widget', {
  widget_type: 'efficiency',
  filters: {...}
})
// Automatically uses queue if endpoint is '/data/widget'
```

**Queue Behavior:**
- âœ… Max concurrent: **6 requests** (browser limit)
- âœ… Automatic detection: Any request to `/data/widget` uses queue
- âœ… FIFO order: First requested = first executed
- âœ… No blocking: UI stays responsive during queue

### 3. **Request Deduplication**

```typescript
// Three widgets load at the same time and need infrastructure options:
Promise.all([
  api.get('/data/infrastructure'), // â³ Makes actual API call
  api.get('/data/infrastructure'), // âš¡ Waits for first call
  api.get('/data/infrastructure')  // âš¡ Waits for first call
])
// Result: Only 1 API call made, all 3 widgets get the data!
```

---

## ğŸ› ï¸ Override Automatic Behavior (Rare Cases)

### Disable Cache for Specific Request:
```typescript
// For real-time data that shouldn't be cached
const liveData = await api.get('/data/live-stats', undefined, { 
  useCache: false 
})
```

### Custom Cache Duration:
```typescript
// Cache for 10 minutes instead of default 5
const data = await api.get('/data/reports', undefined, { 
  cacheDuration: 10 * 60 * 1000 
})
```

### Disable Queue for Specific Request:
```typescript
// For urgent/priority requests
const urgentData = await api.post('/data/widget', {...}, {}, { 
  useQueue: false 
})
```

### Manually Clear Cache:
```typescript
import { api } from '@/lib/api'

// Clear all cache
api.clearCache()

// Clear specific pattern
api.clearCachePattern(/^\/data\/widget/) // Clear all widget cache
```

---

## ğŸ“Š Real-World Example

### Scenario: Dashboard with 6 Efficiency Widgets

**Without Optimizations:**
```
Load Dashboard
â”œâ”€ Widget 1: GET /data/infrastructure (200ms)
â”œâ”€ Widget 2: GET /data/infrastructure (200ms) âŒ DUPLICATE
â”œâ”€ Widget 3: GET /data/infrastructure (200ms) âŒ DUPLICATE
â”œâ”€ Widget 4: GET /data/infrastructure (200ms) âŒ DUPLICATE
â”œâ”€ Widget 5: GET /data/infrastructure (200ms) âŒ DUPLICATE
â”œâ”€ Widget 6: GET /data/infrastructure (200ms) âŒ DUPLICATE
â”œâ”€ Widget 1: POST /data/widget (500ms)
â”œâ”€ Widget 2: POST /data/widget (500ms)
â”œâ”€ Widget 3: POST /data/widget (500ms)
â”œâ”€ Widget 4: POST /data/widget (STALLED) âš ï¸
â”œâ”€ Widget 5: POST /data/widget (STALLED) âš ï¸
â””â”€ Widget 6: POST /data/widget (STALLED) âš ï¸

Total: 12 requests, 3+ seconds, 3 stalled
```

**With Automatic Optimizations:**
```
Load Dashboard
â”œâ”€ Widget 1: GET /data/infrastructure (200ms) âœ… API CALL
â”œâ”€ Widget 2-6: GET /data/infrastructure (<1ms each) âœ… CACHE HIT
â”œâ”€ Widget 1-6: POST /data/widget (queued)
â”‚   â”œâ”€ Slots 1-6: Execute immediately (500ms each)
â”‚   â””â”€ No stalling!

Total: 7 requests (1 GET + 6 POST), 0.7 seconds, 0 stalled
```

**Performance Gain:**
- ğŸš€ **5x fewer requests** (12 â†’ 7)
- âš¡ **4x faster load** (3s â†’ 0.7s)
- âœ… **0 stalled requests** (3 â†’ 0)

---

## ğŸ§ª Testing the Optimizations

### 1. Check Browser Console:
```
[API Cache] Hit: /data/infrastructure   â† Cache is working!
[API Cache] Using pending request: /data/infrastructure   â† Deduplication working!
```

### 2. Check Network Tab (DevTools):
- Should see **1 request** for `/data/infrastructure` (not 6)
- Should see **max 6 concurrent** requests at any time
- Should see **200ms â†’ <1ms** for cached requests

### 3. Check Request Queue:
```typescript
import { requestQueue } from '@/lib/request-queue'

console.log('Active:', requestQueue.getActiveRequests())  // Should be â‰¤ 6
console.log('Queued:', requestQueue.getQueueSize())       // Remaining widgets
```

---

## ğŸ¨ Visual Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Opens Dashboard                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                       â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ GET      â”‚          â”‚ POST     â”‚
    â”‚ Requests â”‚          â”‚ Requests â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚                      â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ ğŸ” Check Cache   â”‚   â”‚ ğŸ” Check Queue    â”‚
    â”‚ âœ… Hit? Return   â”‚   â”‚ âœ… Slot? Execute  â”‚
    â”‚ âŒ Miss? Fetch   â”‚   â”‚ âŒ Full? Queue    â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ ğŸ’¾ Store in Cacheâ”‚   â”‚ â³ Wait for Slot  â”‚
    â”‚ â° TTL: 5 min    â”‚   â”‚ ğŸ¯ Max: 6 active  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## â“ FAQ

### Q: Will this affect my real-time data?
**A:** No! You can disable caching for specific endpoints:
```typescript
api.get('/data/live', undefined, { useCache: false })
```

### Q: What happens if the cache becomes stale?
**A:** Cache automatically expires after 5 minutes. You can also manually clear it:
```typescript
api.clearCache()  // Clear all
api.clearCachePattern(/pattern/)  // Clear specific
```

### Q: Can I see what's happening?
**A:** Yes! Check browser console for cache hit/miss logs:
```
[API Cache] Hit: /data/infrastructure
[API Cache] Using pending request: /data/products
```

### Q: Does this affect POST/PUT/DELETE requests?
**A:** No! Only GET requests are cached. POST/PUT/DELETE always go to the server.
Widget POST requests (`/data/widget`) automatically use the queue to prevent stalling.

### Q: What if I need more than 6 concurrent requests?
**A:** You can adjust the queue size:
```typescript
import { requestQueue } from '@/lib/request-queue'
requestQueue.setMaxConcurrent(10)  // Increase to 10
```

---

## ğŸ‰ Summary

**You don't need to do anything!** All optimizations are automatic:

âœ… GET requests â†’ Cached  
âœ… Widget requests â†’ Queued  
âœ… Duplicate requests â†’ Deduplicated  
âœ… Hanging requests â†’ Timeout after 30s

Just write normal API calls and enjoy the performance boost! ğŸš€

